{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fbe235ef3db30ff7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## normalizer\n",
    "- 使原始语料更加“干净”"
   ],
   "id": "fc8961674ad42b91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T07:42:15.917029Z",
     "start_time": "2025-02-25T07:42:15.906828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------- normalizer ---------------------------------- #\n",
    "\n",
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import NFD, StripAccents\n",
    "normalizer = normalizers.Sequence([NFD(), StripAccents()])\n",
    "\n",
    "normalizer.normalize_str(\"Héllò hôw are ü?\")\n",
    "# \"Hello how are u?\""
   ],
   "id": "82dd649cc30db569",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello how are u?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# tokenizer中可以指定normalizer\n",
    "# tokenizer.normalizer = normalizer"
   ],
   "id": "8cc686b03d304e59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## pre-tokenizer\n",
    "- 预分词器，会将文本分割为最小的token单位。之后vocab_size不会超过此时的分词数量\n",
    "    - 比如利用BPE会合并某些token成为一个新token，vocab_size就变小了"
   ],
   "id": "b5afd470dacedb81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T07:43:50.226141Z",
     "start_time": "2025-02-25T07:43:50.178935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "pre_tokenizer = Whitespace()\n",
    "pre_tokenizer.pre_tokenize_str(\"Hello! How are you? I'm fine, thank you.\")\n",
    "# [(\"Hello\", (0, 5)), (\"!\", (5, 6)), (\"How\", (7, 10)), (\"are\", (11, 14)), (\"you\", (15, 18)),\n",
    "#  (\"?\", (18, 19)), (\"I\", (20, 21)), (\"'\", (21, 22)), ('m', (22, 23)), (\"fine\", (24, 28)),\n",
    "#  (\",\", (28, 29)), (\"thank\", (30, 35)), (\"you\", (36, 39)), (\".\", (39, 40))]"
   ],
   "id": "82ee9c560eb9210a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', (0, 5)),\n",
       " ('!', (5, 6)),\n",
       " ('How', (7, 10)),\n",
       " ('are', (11, 14)),\n",
       " ('you', (15, 18)),\n",
       " ('?', (18, 19)),\n",
       " ('I', (20, 21)),\n",
       " (\"'\", (21, 22)),\n",
       " ('m', (22, 23)),\n",
       " ('fine', (24, 28)),\n",
       " (',', (28, 29)),\n",
       " ('thank', (30, 35)),\n",
       " ('you', (36, 39)),\n",
       " ('.', (39, 40))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 预分词器会输出每个token的开始位置和结束位置\n",
    "- Whitespace会以 \\[空格, tab, 回车\\] 等空白字符为间隔分词\n",
    "\n",
    "可以利用pre_tokenizers.Sequence组合多个预分词器，预分词器会按照顺序执行"
   ],
   "id": "112c8b5da7c15ded"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T07:48:55.620412Z",
     "start_time": "2025-02-25T07:48:55.615052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tokenizers import pre_tokenizers\n",
    "from tokenizers.pre_tokenizers import Digits\n",
    "pre_tokenizer = pre_tokenizers.Sequence([Whitespace(), Digits(individual_digits=True)]) # 可以按顺序组合多个预分词器\n",
    "pre_tokenizer.pre_tokenize_str(\"Call 911!\")\n",
    "# [(\"Call\", (0, 4)), (\"9\", (5, 6)), (\"1\", (6, 7)), (\"1\", (7, 8)), (\"!\", (8, 9))]"
   ],
   "id": "e66b5a99533b7253",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Call', (0, 4)), ('9', (5, 6)), ('1', (6, 7)), ('1', (7, 8)), ('!', (8, 9))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# tokenizer指定预分词器\n",
    "# tokenizer.pre_tokenizer = pre_tokenizer"
   ],
   "id": "cfc94db4f0c9594"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## model\n",
    "- 分别有4类模型：\n",
    "    - models.BPE\n",
    "    - models.Unigram\n",
    "    -"
   ],
   "id": "c5885494bbf9bd31"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
